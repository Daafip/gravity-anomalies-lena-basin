{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7857df2a-31fa-494f-b37e-86c1db94a20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\david\\anaconda3\\envs\\ship\\Lib\\site-packages\\regionmask\\core\\regions.py:9: UserWarning: Shapely 2.0 is installed, but because PyGEOS is also installed, GeoPandas will still use PyGEOS by default for now. To force to use and test Shapely 2.0, you have to set the environment variable USE_PYGEOS=0. You can do this before starting the Python process, or in your code before importing geopandas:\n",
      "\n",
      "import os\n",
      "os.environ['USE_PYGEOS'] = '0'\n",
      "import geopandas\n",
      "\n",
      "In a future release, GeoPandas will switch to using Shapely by default. If you are using PyGEOS directly (calling PyGEOS functions on geometries from GeoPandas), this will then stop working and you are encouraged to migrate from PyGEOS to Shapely 2.0 (https://shapely.readthedocs.io/en/latest/migration_pygeos.html).\n",
      "  import geopandas as gp\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import re\n",
    "import os\n",
    "import regionmask\n",
    "import datetime\n",
    "# to fix MJD\n",
    "import astropy\n",
    "from astropy.time import Time\n",
    "\n",
    "# data management\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "\n",
    "# plotting\n",
    "import matplotlib.pyplot as plt\n",
    "# os.environ['USE_PYGEOS'] = '0'\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "from rasterio.plot import show as rioshow\n",
    "from shapely.geometry import Polygon\n",
    "from geospatial_functions import get_background_map\n",
    "\n",
    "# imported from provided py code: long functions\n",
    "from calc_geoid_change_alt import readstrokescoefficients, plm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3381d043-3d00-47e4-9702-3a70387e159e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading other layers\n",
    "outline           = gpd.read_file(f\"Data\\\\lena_basin_outline_polygon.gpkg\",driver=\"GPKG\")\n",
    "main_rivers       = gpd.read_file(f\"Data\\\\lena_main_river.gpkg\",driver=\"GPKG\")   \n",
    "coast             = gpd.read_file(f\"Data\\\\north_east_russian_coastlines.gpkg\",driver=\"GPKG\")   \n",
    "# fixing crs\n",
    "for layer in [outline,main_rivers,coast]:\n",
    "    layer.geometry = layer.geometry.to_crs(\"EPSG:4326\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb62148-5288-4f3f-917f-0b90e41eb536",
   "metadata": {},
   "source": [
    "background:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf38b6d-4bc0-46c1-8dac-46e696bfee97",
   "metadata": {},
   "source": [
    "Grace can measure $\\frac{\\Delta S}{\\Delta t}$, when looking at the water balance: $\\frac{\\Delta S}{\\Delta t} = P - L$ where $L$ are the losses.\n",
    "\n",
    "Losses are due to Evapotranspiration ($ET$), Discharge ($Q$) and Underground flow (ground water - $G$). \n",
    "\n",
    "Evaporation can be esimated but is difficult, discharge can be considered known: \n",
    "\n",
    "$\\frac{\\Delta S}{\\Delta t} = P - Q - ET - GW$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cc6abb-15cb-4123-a954-10425a0e658f",
   "metadata": {},
   "source": [
    "# first focus on grace data\n",
    "Downloaded data can be loaded in, note using stokes coefficients till 60th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "524c4e05-4769-4d23-959e-70b54bc8b0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "grace_files = glob.glob('Data\\\\Grace_filtered\\*.gfc')\n",
    "love_numbers_kl = np.loadtxt('Data\\\\loadLoveNumbers_60.txt')[:,1]\n",
    "l = 60\n",
    "m = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cb9398-3049-40d4-9e4a-59bedd4ec7f5",
   "metadata": {},
   "source": [
    "Stokes coeffcients order 1& 2 need to be handeled differently\n",
    "\n",
    "order 1: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81738dc2-fe97-4479-b75b-d186634a7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_stoke_coeff1 = f'Data\\\\Grace\\\\degree1_stokes_coeff.txt'\n",
    "df_stokes_1 = pd.read_csv(fname_stoke_coeff1,skiprows=116,delimiter=\" \", \n",
    "        names=['GRCOF2',\"_1\",\"_2\",\"_3\",\"l\",\"_4\",\"_5\",\"m\", \"Clm\",\"Slm\",\"sd_Clm\",\"sd_Slm\",\"begin_date\",\"end_date\"])\n",
    "### drop unwanted\n",
    "df_stokes_1.drop(columns=[\"_1\",\"_2\",\"_3\",\"_4\",\"_5\",\"GRCOF2\",\"sd_Clm\",\"sd_Slm\"],inplace=True)\n",
    "### Reformat dates\n",
    "df_stokes_1[\"end_date\"] = df_stokes_1.apply(lambda x: pd.Timestamp(f'{str(x.end_date)[0:4]}-{str(x.end_date)[4:6]}-{str(x.end_date)[6:8]}'),axis=1)\n",
    "### dirty fix to make more fit\n",
    "df_stokes_1[\"begin_date\"] = df_stokes_1.apply(lambda x: pd.Timestamp(f'{str(x.begin_date)[0:4]}-{str(x.begin_date)[4:6]}-01'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "536518bb-2a6f-48e8-9c5c-31cae3d9bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_0 = df_stokes_1[df_stokes_1['m'] == 0].set_index('begin_date')\n",
    "df_1_1 = df_stokes_1[df_stokes_1['m'] == 1].set_index('begin_date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5621d2d9-215d-414e-9d4f-8b5468655edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# easiest way to fix the indexing in matchting the correct indexes\n",
    "df_index_replace = df_1_1.index.to_numpy().copy()\n",
    "for i, index in enumerate(df_1_1.index):\n",
    "    if i == 0:\n",
    "        pass\n",
    "    if (df_1_1.index[i-1] - index) == pd.Timedelta(0):\n",
    "        replace = pd.Timestamp(f'{index.year}-{index.month+1}-{index.day}')\n",
    "        df_index_replace[i] = replace\n",
    "df_1_1.index = df_index_replace\n",
    "df_1_0.index = df_index_replace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e8c994-e032-4cd4-a919-7d25e4e577df",
   "metadata": {},
   "source": [
    "order 2,0 & 3,0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a05916-f9fe-4d76-a7ae-705621263bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname_stoke_coeff2 = f'Data\\\\Grace\\\\degree2_stokes_coeff.txt'\n",
    "\n",
    "# pd.read_csv didnt work so must read 'manually'\n",
    "reach_end_of_head = False\n",
    "list_lines = []\n",
    "with open(fname_stoke_coeff2) as fin:\n",
    "    for line in fin:\n",
    "        line = line.strip()\n",
    "        if not reach_end_of_head:\n",
    "            if line.startswith(\"Product:\"):\n",
    "                reach_end_of_head = True\n",
    "        else:\n",
    "            line = line.split(' ')\n",
    "            line = np.array(line)\n",
    "            line = line[line!=\" \"]\n",
    "            line = line[line!=\"\"]\n",
    "            list_lines.append(line)\n",
    "arr_lines = np.array(list_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c240b506-2395-42e7-8614-0b00667c96da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MJD_to_ts(mjd):\n",
    "    ## thanks to https://stackoverflow.com/questions/72597699/how-do-i-convert-mjdjulian-date-to-utc-using-astropy\n",
    "    # Start with some time in modified julian date (MJD)\n",
    "    # Convert to Julian Date\n",
    "    mjd = float(mjd)\n",
    "    jd = mjd + 2400000.5\n",
    "    # Convert to astropy Time object\n",
    "    t = astropy.time.Time(jd, format='jd')\n",
    "    # Convert to datetime\n",
    "    str = t.to_datetime()\n",
    "    return str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be465350-bf18-4e21-ba84-93137812180f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert array into df\n",
    "df_stokes_2_3 = pd.DataFrame(arr_lines,\n",
    "               columns=['MJD begin',\"Year fraction begin\",\"C20\",\"C20 - C20_mean (1.0E-10)\",\"sig_C20 (1.0E-10)\",\n",
    "                                                          \"C30\",\"C30 - C30_mean (1.0E-10)\",\"sig_C30 (1.0E-10)\",\n",
    "                    'MJD end',\"Year fraction end\"\n",
    "                   ])\n",
    "# fix date format\n",
    "df_stokes_2_3[\"begin_date\"] = df_stokes_2_3.apply(lambda x: MJD_to_ts(x['MJD begin']), axis=1)\n",
    "df_stokes_2_3[\"end_date\"] = df_stokes_2_3.apply(lambda x: MJD_to_ts(x['MJD begin']), axis=1)\n",
    "df_stokes_2_3 = df_stokes_2_3[[\"begin_date\",\"C20\",\"C30\",\"end_date\"]].set_index(\"begin_date\")\n",
    "\n",
    "# allign indexes and replace like in C_1_1..\n",
    "df_stokes_2_3 = df_stokes_2_3.iloc[:-2] # remove last two months to make same length\n",
    "df_stokes_2_3.index = df_index_replace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56242704-6c88-4c9e-81cb-28e44a23ecef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names and dates needed, obtained from file name\n",
    "# grace_names = [file[-11:-4] for file in grace_files]\n",
    "# times = [pd.Timestamp(grace_names_i) for grace_names_i in grace_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044cceb1-8b71-4669-9f05-50dbc112bda3",
   "metadata": {},
   "source": [
    "Adjust readstokescoefficients to also obtain `time_period_of_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ed577d2-7e25-42e6-b1de-0309d53dd106",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readstrokescoefficients_filtered(filename):\n",
    "    with open(filename) as f:\n",
    "        reach_end_of_head = 0\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if reach_end_of_head == 0:\n",
    "                if line.startswith(\"earth_gravity_constant\"):\n",
    "                    GM = float(line[line.index(\" \") + 1:])\n",
    "                elif \"radius\" in line:\n",
    "                    line = re.sub(' +', ' ', line)\n",
    "                    R = float(line.split(\" \")[1])\n",
    "                elif line.startswith(\"max_degree\"):\n",
    "                    line = re.sub(' +', ' ', line)\n",
    "                    max_degree = int(line.split(\" \")[1])\n",
    "                    C = np.zeros((max_degree + 1, max_degree + 1))\n",
    "                    S = np.zeros((max_degree + 1, max_degree + 1))\n",
    "                elif line.startswith('time_period_of_data'):\n",
    "                    line = re.sub(' +', ' ', line)\n",
    "                    date_line = line.split(\" \")\n",
    "                    begin_date = str(line.split(\" \")[1])\n",
    "                    begin_date_ts = pd.Timestamp(f'{begin_date[0:4]}-{begin_date[4:6]}-01')\n",
    "                    end_date = str(line.split(\" \")[3])\n",
    "                    \n",
    "                else:\n",
    "                    if line.startswith(\"end_of_head\"):\n",
    "                        reach_end_of_head = 1\n",
    "            else:\n",
    "                line = re.sub(' +', ' ', line)\n",
    "                line = line.split()\n",
    "                L = int(line[1])\n",
    "                M = int(line[2])\n",
    "                C[L, M] = float(line[3])\n",
    "                S[L, M] = float(line[4])\n",
    "    return C, S, R, GM, begin_date_ts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "857d684a-a022-4bb3-84b3-feb948c75133",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in all coefficient\n",
    "C, S, times, grace_names = [], [], [], []\n",
    "for i, file in enumerate(grace_files):\n",
    "    C_i, S_i, R, GM, time_i = readstrokescoefficients_filtered(file)\n",
    "    \n",
    "    # replace C_1_0,C_1_1, S_1_1, C_2_0, C_3_0\n",
    "    try:\n",
    "        test  = df_1_0.loc[time_i,\"Clm\"]\n",
    "        new_time = time_i\n",
    "    except KeyError: # issue with finding correct value, this is easiest fix\n",
    "        new_time = pd.Timestamp(f'{time_i.year}-{time_i.month-1}-{time_i.day}')\n",
    "        print(new_time)\n",
    "    \n",
    "    C_i[1,0]  = df_1_0.loc[new_time,\"Clm\"]\n",
    "    C_i[1,1]  = df_1_1.loc[new_time,\"Clm\"]\n",
    "    S_i[1,1]  = df_1_1.loc[new_time,\"Slm\"]\n",
    "    C_i[2,0]  = df_stokes_2_3.loc[new_time,\"C20\"]\n",
    "    C_30  = df_stokes_2_3.loc[new_time,\"C30\"]\n",
    "    if C_30 == \"NaN\": \n",
    "        pass\n",
    "    else: \n",
    "        C_i[3,0] = C_30\n",
    "        \n",
    "    C.append(C_i), S.append(S_i), times.append(time_i), grace_names.append(f'{time_i.year}-{time_i.month}-{time_i.day}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ae106bc-dc6d-4d3d-902d-df818307ef2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get differences for each pair\n",
    "dc1_store = []\n",
    "dc2_store = []\n",
    "ds1_store = []\n",
    "ds2_store = []\n",
    "for i, c in enumerate(C):\n",
    "    if i == 0:\n",
    "        pass # first has no prev\n",
    "    else:\n",
    "        dc1 = C[i]   - ((C[i]    + C[i-1]) / 2)\n",
    "        dc2 = C[i-1] - ((C[i-1]  + C[i]  ) / 2)\n",
    "        ds1 = S[i]   - ((S[i]    + S[i-1]) / 2)\n",
    "        ds2 = S[i-1] - ((S[i-1]  + S[i]  ) / 2)\n",
    "        dc1_store.append(dc1), dc2_store.append(dc2) \n",
    "        ds1_store.append(ds1), ds2_store.append(ds2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6772a4f4-eb40-442e-accd-f0dd1bc91b06",
   "metadata": {},
   "source": [
    "using \n",
    "\\begin{equation}\n",
    "\\delta h_w \\left(\\theta,\\lambda\\right) = \\sum_{l,m=0}^{\\infty}=\\bar{C_{lm}^{\\delta h_w}} \\bar{Y}_{lm}\\left(\\theta,\\lambda\\right)\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60b8f7cf-74ae-46bb-93b8-4b8cad9a0ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "rho_av__rho_w = 5.5 # aprox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a594984b-e0b7-4088-9bda-50da04317cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh_c1_store = []\n",
    "dh_c2_store = []\n",
    "dh_s1_store = []\n",
    "dh_s2_store = []\n",
    "\n",
    "for k, dc1 in enumerate(dc1_store):\n",
    "    C_dhw_i_1 = np.zeros((l+1, l+1))\n",
    "    S_dhw_i_1 = np.zeros((l+1, l+1))\n",
    "    C_dhw_i_2 = np.zeros((l+1, l+1))\n",
    "    S_dhw_i_2 = np.zeros((l+1, l+1))\n",
    "    for i in range(l+1):\n",
    "        for j in range(i+1):\n",
    "            multiplication_factor = (R  * (2 * i + 1) * rho_av__rho_w) / ( 3 * (1 + love_numbers_kl[i]))\n",
    "            C_dhw_i_1[i, j] = (dc1_store[k][i, j] * multiplication_factor)\n",
    "            S_dhw_i_1[i, j] = (ds1_store[k][i, j] * multiplication_factor)\n",
    "            C_dhw_i_2[i, j] = (dc2_store[k][i, j] * multiplication_factor)\n",
    "            S_dhw_i_2[i, j] = (ds2_store[k][i, j] * multiplication_factor)\n",
    "    dh_c1_store.append(C_dhw_i_1), dh_c2_store.append(C_dhw_i_2) \n",
    "    dh_s1_store.append(S_dhw_i_1), dh_s2_store.append(S_dhw_i_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312fc3c3-0e6c-41df-aa05-aab739d6a590",
   "metadata": {},
   "source": [
    "Create array of lat lon for the area: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c418938-806b-4219-adbe-b16c2e7ec9ec",
   "metadata": {},
   "source": [
    "![Figures\\Lena_Basin_map.png](Figures\\Lena_Basin_map.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b938f906-5f05-43d5-a8f3-430e35cbc6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_lambda= [ 90.  91.  92.  93.  94.  95.  96.  97.  98.  99. 100. 101. 102. 103.\n",
      " 104. 105. 106. 107. 108. 109. 110. 111. 112. 113. 114. 115. 116. 117.\n",
      " 118. 119. 120. 121. 122. 123. 124. 125. 126. 127. 128. 129. 130. 131.\n",
      " 132. 133. 134. 135. 136. 137. 138. 139. 140. 141. 142. 143. 144. 145.\n",
      " 146. 147. 148. 149.]\n",
      "\n",
      "\n",
      "theta= [170. 169. 168. 167. 166. 165. 164. 163. 162. 161. 160. 159. 158. 157.\n",
      " 156. 155. 154. 153. 152. 151. 150. 149. 148. 147. 146. 145. 144. 143.\n",
      " 142. 141.]\n"
     ]
    }
   ],
   "source": [
    "_lambda = np.pi/180 * np.array(range(270,330,1)) - np.pi # 90 - 150 # deg lon\n",
    "theta = np.pi - np.pi/180 * np.array(range(10, 40,1)) # 80 - 50 deg lat\n",
    "\n",
    "print('_lambda=',_lambda/np.pi*180)\n",
    "print('\\n')\n",
    "print('theta=',theta/np.pi*180)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e91593b7-ef1b-473a-93bb-2d8f28408d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcad6f56-9fb7-4312-9199-6340102a4fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cube(x):\n",
    "    return math.sqrt(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7e0dee9b-9ec3-4cd1-a32a-0b7bda108944",
   "metadata": {},
   "outputs": [],
   "source": [
    "# N = 500\n",
    "# with Pool() as pool:\n",
    "#     result = pool.map(cube, range(10,N))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a596a215-a55a-4367-82e8-b13a1867943c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<multiprocessing.pool.Pool state=RUN pool_size=12>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e007eb6-141a-45fb-bd93-2ca5fa36a89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = \"Data\\\\anomally_waterhead_filtered_full.nc\"\n",
    "# fname = \"Data\\\\anomally_waterhead_filtered_test.nc\" # debug\n",
    "run = True\n",
    "if run:\n",
    "    store_ewh_1 = []\n",
    "    store_ewh_2 = []\n",
    "    # n=4                                         # debugging\n",
    "    print(datetime.datetime.now())\n",
    "    # for z, dh_c1 in enumerate(dh_c1_store[:n]): # debugging\n",
    "    for z, dh_c1 in enumerate(dh_c1_store):\n",
    "        print(f'{z=}',end='\\n')\n",
    "        ewh_i_1 = np.zeros((len(theta), len(_lambda)))\n",
    "        ewh_i_2 = np.zeros((len(theta), len(_lambda)))\n",
    "        \n",
    "        for i in range(len(theta)):                              # loop over all thetas\n",
    "            # print(f'{i=} (out of {len(theta)})',end='\\r')\n",
    "            P_lm = plm(theta[i], l)                              # all Legendre Functions for one theta\n",
    "            for j in range(len(_lambda)):                        # loop over all lambdas\n",
    "                for k in range(l+1):                             # loop over all degrees\n",
    "                    for t in range(k+1):                         # loop over negative orders\n",
    "                        sin_t_lambda = np.sin(t*_lambda[j])      # negative orders\n",
    "                        cos_t_lambda = np.cos(t*_lambda[j])      # non-negative orders\n",
    "                        # compute here equivalent water heights\n",
    "                        ewh_i_1[i, j] = ewh_i_1[i, j] + (dh_s1_store[z][k, t] * P_lm[k, t] * sin_t_lambda)\n",
    "                        ewh_i_2[i, j] = ewh_i_2[i, j] + (dh_s2_store[z][k, t] * P_lm[k, t] * sin_t_lambda)\n",
    "                        ewh_i_1[i, j] = ewh_i_1[i, j] + (dh_c1_store[z][k, t] * P_lm[k, t] * cos_t_lambda)\n",
    "                        ewh_i_2[i, j] = ewh_i_2[i, j] + (dh_c2_store[z][k, t] * P_lm[k, t] * cos_t_lambda)\n",
    "        print('\\r')\n",
    "        store_ewh_1.append(ewh_i_1)\n",
    "        store_ewh_2.append(ewh_i_2)\n",
    "\n",
    "    # store after itteration\n",
    "    store_ewh = [store_ewh_1[i] - store_ewh_2[i] for i in range(len(store_ewh_1))]\n",
    "    # times = times[:(n+1)]                                                        # debugging\n",
    "    ds = xr.DataArray(store_ewh, dims=(\"time\",\"lat\",\"lon\"),coords={\"lon\":_lambda/np.pi*180,\n",
    "                                                                 \"lat\": np.flip(theta/np.pi*180-90),\n",
    "                                                                 \"time\":times[:-1]}, name=\"dh(m)\")\n",
    "    \n",
    "    ds.to_netcdf(fname)\n",
    "    print(datetime.datetime.now())\n",
    "else:\n",
    "    ds = xr.open_dataset(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed02029-8bbc-47c0-9e8a-8685cfc3ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# times = times[:(n+1)] # debugging\n",
    "# # times = [pd.Timestamp(grace_name,s_i) for grace_names_i in grace_names]\n",
    "# ds = xr.DataArray(store_ewh, dims=(\"time\",\"lat\",\"lon\"),coords={\"lon\":_lambda/np.pi*180,\n",
    "#                                                              \"lat\": np.flip(theta/np.pi*180-90),\n",
    "#                                                              \"time\":times[:-1]}, name=\"dh(m)\")\n",
    "\n",
    "# ds.to_netcdf(fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf3538c5-dd1f-483c-989e-c3d997d809a0",
   "metadata": {},
   "source": [
    "16 = 5min\n",
    "160 = 50min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37937255-2eb1-49c2-a53d-9d4b5a6a9101",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "i = 3\n",
    "ds.isel(time=i)[\"dh(m)\"].plot(ax=ax,cmap=\"viridis\")\n",
    "ax.set_title(f\"Changes between {grace_names[i]} - {grace_names[i+1]}\")\n",
    "outline.plot(ax=ax, edgecolor=\"C3\", facecolor=\"None\")\n",
    "main_rivers.plot(ax=ax, color=\"lightskyblue\",alpha=0.6,lw=1.5)\n",
    "\n",
    "bounds = (90.0, 50.0, 150.0, 80.0)\n",
    "coast.plot(ax=ax,color='k',zorder=1)\n",
    "ax.set_xlim((bounds[0],bounds[2]))\n",
    "ax.set_ylim((bounds[1],bounds[3]));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8509b556-31b9-446f-aa99-3d571e428ff2",
   "metadata": {},
   "source": [
    "Mask the dat using [regionmask](https://regionmask.readthedocs.io/en/stable/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf2e77d-6a40-48aa-8fa5-465274f86dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = regionmask.mask_geopandas(outline, \n",
    "                                 ds.lon.to_numpy(), \n",
    "                                 ds.lat.to_numpy(),\n",
    "                                 lon_name=\"lon\",\n",
    "                                 lat_name=\"lat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3b2485-e868-4af0-902b-d76e49e503ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_lena_basin = ds.where(mask==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f07e0f-5024-4190-9e58-b3110e293234",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ds_lena_basin.isel(time=i)[\"dh(m)\"].plot(ax=ax,cmap=\"viridis\")\n",
    "ax.set_title(f\"Changes between {grace_names[i]} - {grace_names[i+1]}\")\n",
    "outline.plot(ax=ax, edgecolor=\"C3\", facecolor=\"None\")\n",
    "main_rivers.plot(ax=ax, color=\"lightskyblue\",alpha=0.6,lw=1.5)\n",
    "\n",
    "bounds = (90.0, 50.0, 150.0, 80.0)\n",
    "coast.plot(ax=ax,color='k',zorder=1)\n",
    "\n",
    "ax.set_ylabel(\"Latitude (°N)\")\n",
    "ax.set_xlabel(\"Longitude (°E)\")\n",
    "## optionally add background but CRS is difficult\n",
    "\n",
    "# with rasterio.open(get_background_map(\"outline2\", bounds)) as r:\n",
    "#     rioshow(r, ax=ax,zorder=-10)\n",
    "ax.set_xlim((bounds[0],bounds[2]))\n",
    "ax.set_ylim((bounds[1],bounds[3]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7d8748-cc92-469a-b0da-f3e68bc900d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_mask = mask.values.flatten()\n",
    "masked = len(flat_mask[~np.isnan(flat_mask)])\n",
    "unmasked = len(flat_mask[np.isnan(flat_mask)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df00c932-4c78-41de-a05f-2d6a361d9c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_lambda = (_lambda[1] - _lambda[0])\n",
    "d_theta = (theta[0] - theta[1])\n",
    "print(f'spatial resolution of a gridcell is {d_lambda*180/np.pi:.2f}deg lon, {d_theta*180/np.pi:.2f}deg lat')\n",
    "mean_lambda = _lambda.mean()\n",
    "mean_theta = theta.mean()\n",
    "print(f'mean valu a gridcell is {mean_lambda*180/np.pi:.2f}deg lon, {mean_theta*180/np.pi-90:.2f}deg lat')\n",
    "distance_1deg_lat = 110.574 # km\n",
    "distance_1deg_lon = 111.320 * np.cos((mean_theta*180/np.pi-90)*np.pi/180)# km\n",
    "size_1_grid_cell = distance_1deg_lon * distance_1deg_lat\n",
    "area_basin = size_1_grid_cell * masked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a651e9-610c-4621-8ec1-6c12aed2e0cf",
   "metadata": {},
   "source": [
    "Move to a timeseries by integrating over teh area: i.e. adding these together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4a0363-b483-4e8a-b54a-5fb64d834eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "changes_total_water_mass = ds_lena_basin.mean(dim=[\"lat\",\"lon\"])[\"dh(m)\"] * 1000 \n",
    "# changes_total_water_mass_km = changes_total_water_mass/1000 *  area_basin * 10**(-9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a2a0a0-6ce4-423c-8d96-9dc8ea17e97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "changes_total_water_mass[:120].plot(ax=ax)\n",
    "ax.set_xlabel(\"Date\")\n",
    "ax.set_ylabel(\"Mass anomaly   $\\mu \\delta h_w$ [mm]\")\n",
    "ax.set_title(\"Mass anomalies over time in the lena basin\"); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed05b5a3-32b9-44ab-ab85-92a72cdcb4bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots()\n",
    "# changes_total_water_mass_km[:130].plot(ax=ax)\n",
    "# ax.set_xlabel(\"Date\")\n",
    "# ax.set_ylabel(\"Mass anomaly   $\\sum \\delta h_w$ [km^3]\")\n",
    "# ax.set_title(\"Mass anomalies over time in the lena basin\"); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b25821-d9e8-4785-8095-d138fdceb6d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
